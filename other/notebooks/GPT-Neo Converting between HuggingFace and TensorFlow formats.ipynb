{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-Neo | Converting between HuggingFace and TensorFlow formats",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iM5QYdIYNDO"
      },
      "source": [
        "### Converting a TensorFlow model to the HuggingFace (PyTorch) format\n",
        "If you plan to use your model to play with finetuneanon's colab, KboldAI's colab or even mine (an altered version of both), you'll need to convert your model to the PyTorch format. If you used mine or the official GPT-Neo colab to finetune your model, it will be stored on a cloud bucket in the original TensorFlow format.\n",
        "\n",
        "If your model isn't too big, you can use this colab to convert it. Otherwise, you'll need to download the model locally and use the same code here to convert it, and then make it available in your Google Drive so you may use with the playing colabs.\n",
        "\n",
        "## Instructions\n",
        "1. Finetune your model and make it available in yout GCP bucket\n",
        "2. Install GCP CLI on your computer and download the model locally\n",
        "3. Install Python 3.7 on your local machine.\n",
        "4. Use the code here to convert your model.\n",
        "  \n",
        "  * Install transformers locally\n",
        "  * Curl the conversion script\n",
        "  * Download the model from your bucket\n",
        "  * Initiate the conversion\n",
        "\n",
        "* `--tf_checkpoint_path`: local input path for your model checkpoints (the folder where the checkpoint/model files are located)\n",
        "* `--config_file`: `config.json`, located inside the model folder together with checkpoint files.\n",
        "* `--pytorch_dump_path`: path where your converted model will be saved\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fxex2_1oYOdu"
      },
      "source": [
        "print(\"Installing transformers\")\n",
        "!pip3 install git+https://github.com/huggingface/transformers\n",
        "\n",
        "print(\"Cloning conversion script\")\n",
        "!curl https://raw.githubusercontent.com/huggingface/transformers/master/src/transformers/models/gpt_neo/convert_gpt_neo_mesh_tf_to_pytorch.py > /content/convert_gpt_neo_mesh_tf_to_pytorch.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B0VUf-GYimn"
      },
      "source": [
        "# Path settings\n",
        "path_in_bucket =\"gs://amaranth-ai/amaranth-2.7B/\"\n",
        "model_input_dir = '/content/models-temp'\n",
        "model_output_dir = \"/content/hf-models/\"\n",
        "\n",
        "# Copy the downloaded model from your bucket\n",
        "!mkdir -p $model_input_dir $model_output_dir\n",
        "!gsutil -m cp -r $path_in_bucket $model_input_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uFjLgo5YRPO"
      },
      "source": [
        "# Model settings\n",
        "model_name = 'amaranth-2.7B'\n",
        "\n",
        "print(\"Initiating conversion\")\n",
        "!python3 /content/convert_gpt_neo_mesh_tf_to_pytorch.py \\\n",
        "    --tf_checkpoint_path $model_input_dir/$model_name \\\n",
        "    --config_file f\"{model_input_dir}/{model_name}/config.json\" \\\n",
        "    --pytorch_dump_path $model_output_dir\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}